{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Docker container"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following commands:\n",
    "docker run -it --rm -p 8888:8888 -v /Users/sylvain/Data_Science/Kaggle/competition_titanic/datasets:/home/jovyan/datasets jupyter-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Missing Age Data (Model Training and helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelAgePredictor():\n",
    "\t'''\n",
    "\tInstantiate and train a model to guess the age of a passenger\n",
    "\t'''\n",
    "\tdf_age = pd.read_csv(filepath_or_buffer=\"datasets/train.csv\",index_col=0)\n",
    "\tdf_age = df_age.loc[:,[\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "\tdf_age = pd.get_dummies(data=df_age)\n",
    "\tdf_age = df_age.dropna(axis=0)\n",
    "\n",
    "\tageFeatures = df_age.copy()\n",
    "\tageFeatures.drop(labels=\"Age\", axis=1, inplace=True)\n",
    "\tageTarget = df_age.loc[:,\"Age\"]\n",
    "\n",
    "\tagePredictor = LinearRegression()\n",
    "\tagePredictor.fit(X=ageFeatures, y=ageTarget)\n",
    "\n",
    "\treturn agePredictor\n",
    "\n",
    "def guessAge(df):\n",
    "\t'''\n",
    "\tFill the missing ages cell with the most likely value\n",
    " \t'''\n",
    "\tagePredictor = modelAgePredictor()\n",
    "\tfeatures_age = df.loc[df.loc[:,\"Age\"].isna(), [\"Sex\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "\tfeatures_age = pd.get_dummies(data=features_age)\n",
    "\tyhat = agePredictor.predict(X=features_age)\n",
    "\tdf.loc[df.loc[:,\"Age\"].isna(), \"Age\"] = yhat\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "<h3>Missing values</h3>\n",
    "- we will replace the missing values of the cabins by \"unknown\"\n",
    "<br>\n",
    "- we will replace the missing age by the median of the age group\n",
    "<br>\n",
    "- we will drop the two missing embarked\n",
    "<h3>Non numerical values</h3>\n",
    "- Name: we will drop it\n",
    "<br>\n",
    "- Sex: we will encode it (2 catégories)\n",
    "<br>\n",
    "- Ticket: we will drop it\n",
    "<br>\n",
    "- Cabin: we will first drop it, and then try to find a way to encode it and use it\n",
    "<br>\n",
    "- Embarked: we will encode it (3 catégories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df):\n",
    "    \n",
    "    # Replace the value of the missing \"Embarked\" by \"S\" (the most common)\n",
    "    df.loc[df.loc[:,\"Embarked\"].isna(), \"Embarked\"] = df.loc[df.loc[:,\"Embarked\"].isna(), \"Embarked\"].apply(lambda x: \"S\")\n",
    "    # Replace the missing pclass value with the most common one\n",
    "    df.loc[df.loc[:,\"Pclass\"].isna(), \"Pclass\"] = df.loc[df.loc[:,\"Pclass\"].isna(), \"Pclass\"].apply(lambda x: 3)\n",
    "    # Replace the missing Fare values with the mean one\n",
    "    df.loc[df.loc[:,\"Fare\"].isna(), \"Fare\"] = df.loc[df.loc[:,\"Fare\"].isna(), \"Fare\"].apply(lambda x:df.loc[:,\"Fare\"].mean())\n",
    "    # fill the missing age values\n",
    "    df.loc[df.loc[:,\"Age\"].isna(), \"Age\"] = df.loc[df.loc[:,\"Age\"].isna(), \"Age\"].apply(lambda x: df.loc[:,\"Age\"].mean())\n",
    "    # df = guessAge(df=df)\n",
    "    \n",
    "    # drop Name, Ticket and Cabin\n",
    "    df.drop(\n",
    "        labels=[\"Name\", \"Ticket\", \"Cabin\"],\n",
    "        inplace=True,\n",
    "        axis=1\n",
    "        ) \n",
    "\n",
    "    # replace Sex and Embarked with dummy variables\n",
    "    df = pd.get_dummies(data=df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scale the Data (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df=pd.DataFrame):\n",
    "\t'''\n",
    " \tThis function will scale the columns of the data Frame which are not binary and return it\n",
    "  \t'''\n",
    "\tcolumnsName = df.columns\n",
    "\tindexName = df.index\n",
    "\tscaler = StandardScaler()\n",
    "\tscaledColumns = pd.DataFrame(scaler.fit_transform(X=df.loc[:, [\"Pclass\", \"Age\", \"Fare\"]]), columns=[\"Pclass\", \"Age\", \"Fare\"], index=indexName)\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load the Dataset and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\n",
    "\tfilepath_or_buffer=\"datasets/train.csv\",\n",
    " index_col=0\n",
    ")\n",
    "# Clean and scale the data\n",
    "df = cleanData(df)\n",
    "# df = scaleData(df)\n",
    "# create the features and target datasets\n",
    "features = df.copy()\n",
    "features.drop(labels=\"Survived\", axis=1, inplace=True)\n",
    "target = df.loc[:,\"Survived\"].copy()\n",
    "# create the train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>K-Nearest-Neighbors</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is: 0.7430167597765364 and was obtaines with k=13\n"
     ]
    }
   ],
   "source": [
    "bestScore = 0\n",
    "bestK = 0\n",
    "\n",
    "for i in range(1,20):    \n",
    "\tknnModel = KNeighborsClassifier(n_neighbors=i)\n",
    "\tknnModel.fit(X=x_train, y=y_train)\n",
    "\tscore = knnModel.score(X=x_test, y=y_test)\n",
    "\n",
    "\tif score > bestScore:\n",
    "\t\tbestScore = score\n",
    "\t\tbestK = i\n",
    "\n",
    "print(f\"The best score is: {bestScore} and was obtaines with k={bestK}\")     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decision Tree</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree gini has a score of 0.7988826815642458\n",
      "The decision tree entropy has a score of 0.8044692737430168\n",
      "The decision tree log_loss has a score of 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "for hyperParameter in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "\ttreeModel = DecisionTreeClassifier(criterion=hyperParameter,random_state=42, max_depth=5)\n",
    "\ttreeModel.fit(X=x_train, y=y_train)\n",
    "\tscore = treeModel.score(X=x_test, y=y_test)\n",
    "\tprint(f\"The decision tree {hyperParameter} has a score of {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVM classifier with c = 0.01, and kernel = linear, has an accuracy score of: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "bestScore = 0\n",
    "bestC = \"\"\n",
    "bestKernel = \"\"\n",
    "for c in [0.001, 0.01, 0.1, 1]:\n",
    "\tfor kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "\t\tsvmModel = SVC(C=c, kernel = kernel)\n",
    "\t\tsvmModel.fit(X=x_train, y=y_train)\n",
    "\t\tscore = svmModel.score(X=x_test, y=y_test)\n",
    "\t\tif score > bestScore:\n",
    "\t\t\tbestC = c\n",
    "\t\t\tbestScore = score\n",
    "\t\t\tbestKernel = kernel\n",
    "print(f\"The SVM classifier with c = {bestC}, and kernel = {bestKernel}, has an accuracy score of: {bestScore}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegModel = LogisticRegression(max_iter=100, solver=\"newton-cg\")\n",
    "logRegModel.fit(X=x_train, y=y_train)\n",
    "logRegModel.score(X=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8013468013468014"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegModel.fit(X=features, y=target)\n",
    "logRegModel.score(X=features, y=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperParameter = [{\n",
    "#     \"C\": [0.3, 1, 3],\n",
    "#     \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "#     \"gamma\": [\"scale\", \"auto\"],\n",
    "#     \"decision_function_shape\": [\"ovo\", \"ovr\"],\n",
    "# }]\n",
    "\n",
    "# svmEstimator = SVC()\n",
    "\n",
    "# svm_cv = GridSearchCV(\n",
    "# \testimator=svmEstimator,\n",
    "# \tparam_grid=hyperParameter,\n",
    "#  \tcv=4,\n",
    "#   \tscoring=\"accuracy\"\n",
    "# )\n",
    "\n",
    "# svm_cv.fit(X=x_train, y=y_train)\n",
    "# svm_cv.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Search the best parameter for a tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826063787001287"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_depth': [2*n for n in range(1,10)],\n",
    "     'max_features': ['sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree_cv = GridSearchCV(\n",
    "     estimator=tree,\n",
    "     param_grid=parameters,\n",
    "     cv=8\n",
    ")\n",
    "\n",
    "tree_cv.fit(X=features, y=target)\n",
    "tree_cv.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make a prediction for the competition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(filepath_or_buffer=\"datasets/test.csv\", index_col=0)\n",
    "# Save the index\n",
    "resDic = {\"PassengerId\": df.index}\n",
    "# Clean and scale the data\n",
    "df = cleanData(df)\n",
    "df = scaleData(df)\n",
    "# Choose a model to assign\n",
    "bestModel = tree_cv\n",
    "# make the prediction\n",
    "resDic[\"Survived\"] = bestModel.predict(X=df)\n",
    "# save it in a DataFrame\n",
    "prediction = pd.DataFrame(data=resDic)\n",
    "# make the prediction an integer\n",
    "prediction.loc[:,\"Survived\"] = prediction.loc[:,\"Survived\"].apply(lambda x:int(x))\n",
    "# save the prediction\n",
    "prediction.to_csv(path_or_buf=\"datasets/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
