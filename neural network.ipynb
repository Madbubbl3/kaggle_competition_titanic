{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Docker container"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following commands:\n",
    "docker run -it --rm -p 8888:8888 -v /Users/sylvain/Data_Science/Kaggle/competition_titanic/datasets:/home/jovyan/datasets jupyter-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df):\n",
    "    \n",
    "    # Replace the value of the missing \"Embarked\" by \"S\" (the most common)\n",
    "    df.loc[df.loc[:,\"Embarked\"].isna(), \"Embarked\"] = df.loc[df.loc[:,\"Embarked\"].isna(), \"Embarked\"].apply(lambda x: \"S\")\n",
    "    # Replace the missing pclass value with the most common one\n",
    "    df.loc[df.loc[:,\"Pclass\"].isna(), \"Pclass\"] = df.loc[df.loc[:,\"Pclass\"].isna(), \"Pclass\"].apply(lambda x: 3)\n",
    "    # Replace the missing Fare values with the mean one\n",
    "    df.loc[df.loc[:,\"Fare\"].isna(), \"Fare\"] = df.loc[df.loc[:,\"Fare\"].isna(), \"Fare\"].apply(lambda x:df.loc[:,\"Fare\"].mean())\n",
    "    # fill the missing age values\n",
    "    df.loc[df.loc[:,\"Age\"].isna(), \"Age\"] = df.loc[df.loc[:,\"Age\"].isna(), \"Age\"].apply(lambda x: df.loc[:,\"Age\"].mean())\n",
    "    # df = guessAge(df=df)\n",
    "    \n",
    "    # drop Name, Ticket and Cabin\n",
    "    df.drop(\n",
    "        labels=[\"Name\", \"Ticket\", \"Cabin\"],\n",
    "        inplace=True,\n",
    "        axis=1\n",
    "        ) \n",
    "\n",
    "    # replace Sex and Embarked with dummy variables\n",
    "    df = pd.get_dummies(data=df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(df=pd.DataFrame):\n",
    "\t'''\n",
    " \tThis function will scale the columns of the data Frame which are not binary and return it\n",
    "  \t'''\n",
    "\tcolumnsName = df.columns\n",
    "\tindexName = df.index\n",
    "\tscaler = StandardScaler()\n",
    "\tscaledColumns = pd.DataFrame(scaler.fit_transform(X=df.loc[:, [\"Age\", \"Fare\"]]), columns=[\"Age\", \"Fare\"], index=indexName)\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering_1(df:pd.DataFrame):\n",
    "    \n",
    "\t# define the helper functions\n",
    "\tdef isClassMember(x, classTicket):\n",
    "\t\tif x == classTicket:\n",
    "\t\t\treturn 1\n",
    "\t\treturn 0\n",
    "\n",
    "\tdef singleOrCouple(x):\n",
    "\t\tif x>0:\n",
    "\t\t\treturn 1\n",
    "\t\treturn 0\n",
    "\n",
    "\tdef oneOrMore(x):\n",
    "\t\tif x>0:\n",
    "\t\t\treturn 1\n",
    "\t\treturn 0\n",
    "\n",
    "\t# encode the new features\n",
    "\tdf[\"siblings\"] = df.loc[:,\"SibSp\"].apply(lambda x: oneOrMore(x))\n",
    "\tdf[\"couple\"] = df.loc[:,\"Parch\"].apply(lambda x:singleOrCouple(x))\n",
    "\tdf[\"firstClass\"] = df.loc[:,\"Pclass\"].apply(lambda x:isClassMember(x, 1))\n",
    "\tdf[\"secondClass\"] = df.loc[:,\"Pclass\"].apply(lambda x:isClassMember(x, 2))\n",
    "\tdf[\"thirdClass\"] = df.loc[:,\"Pclass\"].apply(lambda x:isClassMember(x, 3))\n",
    "\t\n",
    "\t# drop the old ones\n",
    "\tdf = df.drop(labels=[\"Pclass\", \"SibSp\", \"Parch\"], axis=1)\n",
    " \n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfPipeline(df:pd.DataFrame):\n",
    "\tdf = cleanData(df)\n",
    "\tdf = featureEngineering_1(df)\n",
    "\tdf = scaleData(df)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\n",
    "\tfilepath_or_buffer=\"datasets/train.csv\",\n",
    " index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and scale the data\n",
    "df = dfPipeline(df)\n",
    "# create the features and target datasets\n",
    "features = df.copy()\n",
    "features.drop(labels=\"Survived\", axis=1, inplace=True)\n",
    "target = df.loc[:,\"Survived\"].copy()\n",
    "# create the train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [len(x_train.columns)]\n",
    "X=features\n",
    "Y=target\n",
    "x=x_train\n",
    "y=y_train\n",
    "\n",
    "model = keras.Sequential([\n",
    "\tlayers.Dense(units = 256, input_shape = INPUT_SHAPE, activation=\"relu\"),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.Dropout(0.3),\n",
    " \tlayers.Dense(units = 512, activation=\"relu\"),\n",
    "\t# layers.BatchNormalization(),\n",
    "\tlayers.Dropout(0.3),\n",
    "  \tlayers.Dense(units = 256, activation=\"relu\"),\n",
    "\t# layers.BatchNormalization(),\n",
    "\tlayers.Dropout(0.3),\n",
    "\tlayers.Dense(units = 1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=\"adam\",\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\tmetrics=[\"binary_accuracy\"],\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "\tpatience = 50,\n",
    " \tmin_delta = 0.01,\n",
    "\trestore_best_weights = True,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "training_history = model.fit(\n",
    "\tx=X,\n",
    "\ty=Y,\n",
    "\tvalidation_data = (\n",
    "\t\tx_test,\n",
    "\t\ty_test,\n",
    "\t),\n",
    "\tbatch_size = 256,\n",
    "\tepochs = 1250,\n",
    " \tcallbacks = [early_stopping],\n",
    "\tverbose = False,\n",
    ")\n",
    "\n",
    "# see the training history\n",
    "history_df = pd.DataFrame(training_history.history)\n",
    "history_df.loc[10:,:].plot()\n",
    "best_val_acc = history_df.loc[:,\"val_binary_accuracy\"].max()\n",
    "print(f\"The best validation accuray is = {best_val_acc}\")\n",
    "mean_val_acc = history_df.iloc[-10:,3].mean()\n",
    "print(f\"The mean validation accuray is = {mean_val_acc}\")\n",
    "mean_val_acc = history_df.iloc[-10:,1].mean()\n",
    "print(f\"The mean accuray is = {mean_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe best validation accuray is = 0.834080696105957\\nThe mean validation accuray is = 0.8255605340003968\\nThe mean accuray is = 0.8191919267177582\\n'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The best validation accuray is = 0.834080696105957\n",
    "The mean validation accuray is = 0.8255605340003968\n",
    "The mean accuray is = 0.8191919267177582\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make a prediction for the competition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/d2yjkd7s22zcny48m8_01qpm0000gn/T/ipykernel_17720/582279598.py:21: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  prediction.loc[:,\"Survived\"] = prediction.loc[:,\"Survived\"].apply(lambda x:round(x))\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(filepath_or_buffer=\"datasets/test.csv\", index_col=0)\n",
    "\n",
    "# Save the index\n",
    "resDic = {\"PassengerId\": df.index}\n",
    "\n",
    "# Clean and scale the data\n",
    "df = dfPipeline(df)\n",
    "\n",
    "# make the prediction\n",
    "temp = model.predict(df)\n",
    "pred = []\n",
    "for arr in temp:\n",
    "    pred.append(arr[0])\n",
    "resDic[\"Survived\"] = pred\n",
    "\n",
    "# save it in a DataFrame\n",
    "prediction = pd.DataFrame(data=resDic)\n",
    "\n",
    "# make the prediction an integer\n",
    "prediction.loc[:,\"Survived\"] = prediction.loc[:,\"Survived\"].apply(lambda x:round(x))\n",
    "\n",
    "# save the prediction\n",
    "prediction.to_csv(path_or_buf=\"datasets/predictionNN6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ace9aa8434a9d5c5c6a8052162ba46c76a6a3f3d25e308a1c145b34237d17b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
